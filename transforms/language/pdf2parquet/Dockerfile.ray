ARG BASE_IMAGE=docker.io/rayproject/ray:2.24.0-py310

FROM ${BASE_IMAGE}

# see https://docs.openshift.com/container-platform/4.17/openshift_images/create-images.html#use-uid_create-images
USER root
RUN chown ray:root /home/ray && chmod g=u /home/ray
USER ray

RUN pip install --upgrade --no-cache-dir pip 

# install pytest
RUN pip install --no-cache-dir pytest

ARG PIP_INSTALL_EXTRA_ARGS
ARG DPK_WHEEL_FILE_NAME

RUN \
    sudo apt-get update \
    # for opencv, towhee
    && sudo apt-get install -y libgl1 libglib2.0-0 curl wget \
    && sudo apt-get clean

# Copy and install data processing libraries 
# These are expected to be placed in the docker context before this is run (see the make image).
COPY --chmod=775 --chown=ray:root data-processing-dist data-processing-dist
RUN  pip install data-processing-dist/${DPK_WHEEL_FILE_NAME}[ray]
    

## Copy the python version of the tansform
COPY --chmod=775 --chown=ray:root dpk_pdf2parquet/ dpk_pdf2parquet/
COPY --chmod=775 --chown=ray:root requirements.txt requirements.txt
RUN pip install ${PIP_INSTALL_EXTRA_ARGS} -r requirements.txt



# Download models
RUN python -c 'from deepsearch_glm.utils.load_pretrained_models import load_pretrained_nlp_models; load_pretrained_nlp_models(verbose=True);'
# RUN python -c 'from docling.document_converter import DocumentConverter; from pathlib import Path; DocumentConverter.download_models_hf(local_dir=Path("./artifacts/"));'
RUN python -c 'from docling.pipeline.standard_pdf_pipeline import StandardPdfPipeline; s=StandardPdfPipeline.download_models_hf(); print(f"Models cached in {s}")'

# Set environment
ENV PYTHONPATH /home/ray

# Parallelism
ENV OMP_NUM_THREADS=2

# Put these at the end since they seem to upset the docker cache.
ARG BUILD_DATE
ARG GIT_COMMIT
LABEL build-date=$BUILD_DATE
LABEL git-commit=$GIT_COMMIT
